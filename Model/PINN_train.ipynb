{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716b68bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8f18cb19ebe7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#PINN 모델 학습 후 저장, PINN 가중치별 성능 비교 값 출력\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrain_Test_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mx_scaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_scaler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_x_sc_tn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y_sc_tn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Model'"
     ]
    }
   ],
   "source": [
    "#PINN 모델 학습 후 저장, PINN 가중치별 성능 비교 값 출력\n",
    "from Train_Test_dataset import train_dataset, val_dataset,  x_scaler, y_scaler,test_x_sc_tn, test_y_sc_tn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import  DataLoader\n",
    "import ANNs_class as ANN\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "exponents = np.linspace(-7, -5, 10)  \n",
    "fine_tuned_values = 10 ** exponents  \n",
    "list_aci = []\n",
    "\n",
    "# loss_pw 설정\n",
    "for loss_w in fine_tuned_values:\n",
    "    loss_pw = 1 - loss_w\n",
    "    \n",
    "class lbPINN_graph:\n",
    "    def __init__(self,loss_pw_list, loss_w_list, train_loss_list, val_loss_list, best_val_loss_list, cov_list, r2_list,Pf_list, model_list, train_costs_list, train_costs_p_list):\n",
    "        self.loss_pw_list = loss_pw_list\n",
    "        self.loss_w_list = loss_w_list\n",
    "        self.train_loss_list = train_loss_list\n",
    "        self.val_loss_list = val_loss_list\n",
    "        self.best_val_loss_list = best_val_loss_list\n",
    "        self.cov_list = cov_list\n",
    "        self.r2_list = r2_list\n",
    "        self.Pf_list = Pf_list\n",
    "        self.model_list = model_list\n",
    "        self.train_costs_list = train_costs_list\n",
    "        self.train_costs_p_list = train_costs_p_list\n",
    "        \n",
    "    def train_loss(self):\n",
    "        for i in range(len(self.model_list)):\n",
    "            plt.title(f'ANN wts : {self.loss_w_list[i]} + ACI wts :{self.loss_pw_list[i]}')\n",
    "            plt.semilogy(self.train_costs_list[i], label = 'ann_loss')\n",
    "            plt.semilogy(self.train_costs_p_list[i], label = 'aci_loss')\n",
    "            plt.semilogy(self.train_loss_list[i], label = 'total_loss')\n",
    "            plt.semilogy(self.val_loss_list[i], label = 'total_val_loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "    \n",
    "    def lbPINNs_result(self):\n",
    "        fig, (ax1, ax3) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        \n",
    "        x_under = self.loss_pw_list\n",
    "        x_on = self.loss_w_list\n",
    "        y_left = self.cov_list\n",
    "        y_right = self.r2_list\n",
    "        Pf_graph = self.Pf_list\n",
    "\n",
    "        ax1.semilogx(x_under, y_left, 'r-', marker='^', label='Cov')\n",
    "        ax1.set_xlabel('ACI_wts')\n",
    "        ax1.set_ylabel('lbPINNs CoV', color='r')\n",
    "        ax1.tick_params(axis='y', labelcolor='r')\n",
    "\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.semilogx(x_under, y_right, 'b-', marker='o', label='R2 score')\n",
    "        ax2.set_ylabel('lbPINNs R2', color='b')\n",
    "        ax2.tick_params(axis='y', labelcolor='b')\n",
    "\n",
    "        ax1.grid(True)\n",
    "        ax1.set_title('Comparing lbPINNs loss weightings')\n",
    "\n",
    "        ax3.semilogx(x_under, Pf_graph, 'g-', marker='s', label='Test Data')\n",
    "        ax3.set_xlabel('ACI_wts')\n",
    "        ax3.set_ylabel('Test Data Values', color='g')\n",
    "        ax3.tick_params(axis='y', labelcolor='g')\n",
    "\n",
    "        # Add grid and title to the right plot\n",
    "        ax3.grid(True)\n",
    "        ax3.set_title('Pf = len(pred>y)/len(pred+y)')\n",
    "\n",
    "        # Adjust the layout\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Show the plot\n",
    "        plt.show()  \n",
    "\n",
    "def for_ACI(x_data, x_scaler): #x_data = sc_tn\n",
    "    x_data_unsc_tn = x_scaler.inverse_transform(x_data)\n",
    "    fcm = x_data_unsc_tn[:,2]\n",
    "    Ld = x_data_unsc_tn[:,1]\n",
    "    db = x_data_unsc_tn[:,3]\n",
    "    aci_y_unsc = (Ld*torch.sqrt(fcm))/(0.19*db)\n",
    "    #aci_y_sc  = y_scaler.transform(aci_y_unsc)\n",
    "    return aci_y_unsc # output type : unscaled tensor\n",
    "\n",
    "def for_pinn_training(device, model, criterion, optimizer, nb_epochs, train_dataloader, validation_dataloader, x_scaler, y_scaler, loss_p_num):\n",
    "    loss_num = 1-loss_p_num\n",
    "    torch.manual_seed(12)\n",
    "    model = model.to(device)\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    ann_losses =[]\n",
    "    aci_losses =[]\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_wts = None\n",
    "    best_epoch = -1\n",
    "    \n",
    "    for epoch in range(nb_epochs + 1):\n",
    "        model.train()  # 모델을 훈련 모드로 설정\n",
    "        train_loss1 = 0\n",
    "        ann_loss1 = 0\n",
    "        aci_loss1 = 0\n",
    "\n",
    "        for data in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            x, y = data \n",
    "            x = x.to(device) # sc_tn, torch.Size([27(batch size), 14])\n",
    "            y_train = y.to(device) #sc_tn x: torch.Size([27]) => loss 구할때 view(-1,1)하기 \n",
    "            p_train = model(x) \n",
    "            ann_loss = criterion(p_train, y_train)\n",
    "            #print('ann_loss:',ann_loss)\n",
    "            aci_unsc_y = for_ACI(x, x_scaler).view(-1,1)\n",
    "            p_train_unsc = y_scaler.inverse_transform(p_train)\n",
    "            aci_loss = criterion(p_train_unsc ,aci_unsc_y)\n",
    "            #print('aci_loss:', aci_loss)\n",
    "            total_loss = loss_num*ann_loss + loss_p_num*aci_loss \n",
    "            #print(f'total_loss({total_loss}) = {loss_num}*ann_loss({ann_loss}) + {loss_p_num}*aci_loss({aci_loss})')\n",
    "\n",
    "            total_loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            #print('next_total loss:', total_loss)\n",
    "            train_loss1 += total_loss.item()\n",
    "            #print('last total loss:', train_loss1)\n",
    "            ann_loss1 += ann_loss.item()\n",
    "            #print('ann_loss:', ann_loss1)\n",
    "            aci_loss1 += aci_loss.item()\n",
    "            #print('aci_loss:', aci_loss1)\n",
    "        \n",
    "        # 모델 검증\n",
    "        model.eval()  # 모델을 평가 모드로 설정\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for val_data in validation_dataloader:\n",
    "                x_val, y_val = val_data\n",
    "                x_val = x_val.to(device)\n",
    "                p_val = model(x_val)\n",
    "                aci_y_val = for_ACI(x_val, x_scaler).view(-1,1) #unsc_tn\n",
    "                \n",
    "                p_val_unsc = y_scaler.inverse_transform(p_val)\n",
    "                \n",
    "                val_cost_p = criterion(aci_y_val, p_val_unsc)\n",
    "                val_cost = criterion(p_val , y_val)\n",
    "                \n",
    "                total_val_loss = ((loss_num)*val_cost + (loss_p_num)*val_cost_p)\n",
    "                val_loss += total_val_loss.item()\n",
    "        \n",
    "        # calculate mean for each batch\n",
    "        avg_train_loss = train_loss1 / len(train_dataloader)\n",
    "        avg_val_loss = val_loss / len(validation_dataloader)\n",
    "        avg_ann_loss = ann_loss1/ len(train_dataloader)\n",
    "        avg_aci_loss = aci_loss1/len(train_dataloader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        ann_losses.append(avg_ann_loss)\n",
    "        aci_losses.append(avg_aci_loss)\n",
    "        \n",
    "    \n",
    "        if epoch % 100== 0:\n",
    "            print(f\"Epoch: {epoch:4d}/{nb_epochs} - Train Loss: {avg_train_loss:.6f} - Val Loss: {avg_val_loss:.6f}\")\n",
    "        \n",
    "         # Check for best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_wts = model.state_dict().copy()\n",
    "            best_epoch = epoch\n",
    "            epochs_since_improvement = 0\n",
    "            print(f\"New best model found at epoch {epoch} with val loss {avg_val_loss:.6f}\")\n",
    "        else:\n",
    "            epochs_since_improvement += 1\n",
    "        \n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, train_losses, val_losses, best_val_loss, ann_losses, aci_losses\n",
    "\n",
    "def for_pinn_testing(model_pinn, test_x_sc_tn, test_y_sc_tn, device, y_scaler, title):\n",
    "    #model_pinn.eval() 상관없음 \n",
    "    test_y_unsc_tn = y_scaler.inverse_transform(test_y_sc_tn)\n",
    "    test_y_unsc_np = test_y_unsc_tn.detach().cpu().numpy()\n",
    "    test_x_sc_tn = test_x_sc_tn.to(device)\n",
    "    \n",
    "    #pinn\n",
    "    pred_sc_tn = model_pinn(test_x_sc_tn) #torch.Size([54, 1])\n",
    "    indices = (pred_sc_tn > test_y_sc_tn).nonzero(as_tuple=True)[0].tolist() #\n",
    "    Pf = len(indices)/ len(test_y_sc_tn)#\n",
    "    pred_unsc_tn = y_scaler.inverse_transform(pred_sc_tn) #torch.Size([54, 1])\n",
    "    test_y_unsc_tn = y_scaler.inverse_transform(test_y_sc_tn) #torch.Size([54])\n",
    "\n",
    "    div = test_y_unsc_tn/pred_unsc_tn #torch.Size([54, 1])\n",
    "    cov = torch.std(div)/torch.mean(div) #torch.Size([])\n",
    "    cov = cov.item()\n",
    "    predict_np = pred_unsc_tn.detach().cpu().numpy()\n",
    "    ss_res = np.sum((test_y_unsc_np - predict_np)**2)\n",
    "    ss_tot = np.sum((test_y_unsc_np - np.mean(test_y_unsc_np))**2)\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    #r2 = r2_score(test_y_unsc_np, predict_np)\n",
    "\n",
    "    return cov, r2, Pf\n",
    "def make_various_final_PINN(device, nb_epochs, train_dataloader, validation_dataloader, x_scaler, y_scaler, test_x_sc_tn, test_y_sc_tn):\n",
    "    train_loss_list=[]\n",
    "    val_loss_list=[]\n",
    "    best_val_loss_list =[]\n",
    "    cov_list=[]\n",
    "    r2_list =[]\n",
    "    Pf_list =[]\n",
    "    model_list =[]\n",
    "    loss_pw_list = []\n",
    "    loss_w_list = []\n",
    "    train_costs_list =[]\n",
    "    train_costs_p_list =[]\n",
    "    #t = -11\n",
    "    exponents = np.linspace(-7, -5, 10)  \n",
    "    fine_tuned_values_aci = 10 ** exponents\n",
    "    t = fine_tuned_values_aci   \n",
    "    #t = [3e-07]\n",
    "    #t = [-11,3e-07,1e-09,5e-08, 1e-06,1e-05]\n",
    "    #t = [0, 1e-09, 2e-09, 1e-08, 5e-08, 1e-07, 5e-07, 1e-06, 5e-06, 1e-05]\n",
    "    #t = np.arange(0,1e-6, 2e-8)\n",
    "    #for i in range(t, 1):\n",
    "    #for i in t:\n",
    "    #    if i == -11: #0: #t\n",
    "    #        loss_pw = 0\n",
    "    #    else :\n",
    "    #        loss_pw = 10**i #10**i\n",
    "    #    loss_w = 1 - loss_pw\n",
    "          \n",
    "    #exponents = np.arange(-10, 1, 1, dtype=float)\n",
    "    #fine_tuned_values = np.sort(np.concatenate([10**exponents, 5 * 10**(exponents - 1)]))\n",
    "\n",
    "    for loss_pw in fine_tuned_values:\n",
    "        loss_w = 1 - loss_pw\n",
    "        \n",
    "        model = ANN.ANN_batch_4(14,83,39,49,83,1).to(device).double()\n",
    "        criterion = nn.MSELoss().to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = 0.03444508252211158, weight_decay= 0)\n",
    "        \n",
    "        def reset_weights(m):\n",
    "            if isinstance(m, torch.nn.Linear):\n",
    "                m.reset_parameters()\n",
    "        \n",
    "        model.apply(reset_weights)\n",
    "        \n",
    "\n",
    "        trained_model, train_losses, val_losses, best_val_loss, train_costs, train_costs_p = for_pinn_training(device, model, criterion, optimizer, nb_epochs, train_dataloader, validation_dataloader, x_scaler, y_scaler, loss_pw)\n",
    "        trained_model_cov, trained_model_r2, trained_model_Pf = for_pinn_testing(trained_model, test_x_sc_tn, test_y_sc_tn, device, y_scaler, title=None)\n",
    "        \n",
    "        train_loss_list.append(train_losses)\n",
    "        val_loss_list.append(val_losses)\n",
    "        best_val_loss_list.append(best_val_loss)\n",
    "        cov_list.append(trained_model_cov)\n",
    "        r2_list.append(trained_model_r2)\n",
    "        Pf_list.append(trained_model_Pf)\n",
    "        model_list.append(trained_model)\n",
    "        loss_pw_list.append(loss_pw)\n",
    "        loss_w_list.append(loss_w)\n",
    "        train_costs_list.append(train_costs)\n",
    "        train_costs_p_list.append(train_costs_p)\n",
    "        \n",
    "\n",
    "    return loss_pw_list, loss_w_list, train_loss_list, val_loss_list, best_val_loss_list, cov_list, r2_list,Pf_list, model_list, train_costs_list, train_costs_p_list\n",
    "\n",
    "\n",
    "\n",
    "#device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator=torch.Generator().manual_seed(44) #42\n",
    "#criterion4 = nn.MSELoss().to(device) \n",
    "model_final_pinn = ANN.ANN_batch_4(14,83,39,49,83,1).to(device).double()\n",
    "optimizer4 = torch.optim.Adam(model_final_pinn.parameters(), lr =  0.03444508252211158) #\n",
    "ann4_train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True, generator=generator) # 데이터 고정\n",
    "ann4_validation_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=True, generator=generator) #데이터 고정n4_validation_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=True, generator=generator) #데이터 고정\n",
    "\n",
    "\n",
    "a1,b1,c1,d1,e1,f1, g1, p1, h1, i1 ,j1  =make_various_final_PINN(device, 1000, ann4_train_dataloader, ann4_validation_dataloader, x_scaler, y_scaler,test_x_sc_tn, test_y_sc_tn)\n",
    "results = lbPINN_graph(a1,b1,c1,d1,e1,f1, g1,p1, h1, i1 ,j1)\n",
    "results.train_loss()\n",
    "results.lbPINNs_result()\n",
    "\n",
    "aci_wts_list = a1 \n",
    "ann_wts_list = b1\n",
    "model_list = h1 # 여러 PINN 모델들 \n",
    "\n",
    "def make_model_pairs(models, titles):\n",
    "    return list(zip(models, titles))\n",
    "\n",
    "pairs = make_model_pairs(model_list[:], aci_wts_list[:])\n",
    "\n",
    "final_pinn_df = pd.DataFrame({\n",
    "    'ACI_wts':a1,\n",
    "    'ANN_wts':b1,\n",
    "    'CoV': f1,\n",
    "    'R2_score':g1,\n",
    "    'Pf':p1\n",
    "})\n",
    "final_pinn_df['ANN_wts'] = 1-final_pinn_df['ACI_wts']\n",
    "final_pinn_df[['CoV','R2_score','Pf']] = final_pinn_df[['CoV','R2_score','Pf']].round(2)\n",
    "\n",
    "print(final_pinn_df)\n",
    "\n",
    "#적당한 PINN 모델 저장  \n",
    "#torch.save(model_list[4].state_dict(), 'trained_model/Pinn4_58_24_new.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cb8662",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
